model_name: pythia-14m
logger_name: tensorboard
resume: false
devices: auto
seed: 42
data: OpenWebText
out_dir: out/pretrain/debug
tokenizer_dir: checkpoints/EleutherAI/pythia-14m
train:
  save_interval: 1000
  log_interval: 1
  global_batch_size: 125
  micro_batch_size: 5
  lr_warmup_steps: 100
  epochs: null
  max_tokens: 100000000
  max_steps: null
  max_seq_length: null
  tie_embeddings: null
  learning_rate: 6e-4
  weight_decay: 1e-1
  beta1: 0.9
  beta2: 0.95
  max_norm: 1.0
  min_lr: 6e-5
eval:
  interval: 1000
  max_new_tokens: null
  max_iters: 100
